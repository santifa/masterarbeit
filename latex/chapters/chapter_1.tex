
\section{Introduction}
\label{sec_1}

% Motivation
\begin{quote}
A distributed system is one in which the failure of a computer you didn't even
know existed can render your own computer unusable. - Leslie Lamport
\end{quote}

Since the begin of the last century the pace of societies development increases
at an ever increasing speed. Due to, upcoming of modern technology and computer
systems after the second world war. Computer systems started out as single
mounstrous machines operated by a hand-full of designated scientists on
their own. At the late 60s the Arpanet tries to connect all these individual
machines building computational networks of mainframes. Since then the
modern computer systems changed. Their becoming cheaper and more powerfull
by introducing multicore CPUs and a whole loot of other technologies.
A modern desktop computer systems beats an old mainframe by computational power,
space and pricing by orders of magnitude. Also, pluggable small computers
find their way to markets offering low costs and a near desktop like experience.
The networks between computers increased either way by performance and
networking.

These two developments (networking and performance) makes it inevitable
to build modern systems out of multiple larger and not so large computer
systems connected by high-speed connections. Since these networks are fast
enough there is no need for the computer system to be at the same geographically
position. Computers building such a network are called distributed systems
which scale from a hand-full of systems to thousands of computing devices. 
Andrew S. Tanenbaum and Maarten van Steen described such a systems as:

\begin{quote}
  A distributed system is a collection of autonomous computing elements
  that appears to its users as a single coherent system.~\cite{tanenbaum2017distributed}
\end{quote}

From this weak specification follows that a distributed system is not a fixed
number of computing devices but a highly dynamic system where computers can
join, leave or fail and the topology and the network connections can change.
Each system is able to behave independently from all other systems in limited
ways and at every moment a user interacts with this system as if it were one.

These two main aspects implies the need for abstracting away common components
of a distributed system in a transparent way. Distributed systems shall be
geographically divers, speed up computations through the amount of nodes,
handle ressource sharing within the network and be fault-tolerant in limited
ways.

But why build such complex systems which scale from a single computer system
to thousands of nodes? There is a wide range of applications which are used in
everyday life ranging from data intensive to computational intensive
applications. For example modern weather forecasting uses multiple complex
models to describe and compute the possible weather for the next days.
Banking software should run reliable across all bank branches, ATMs and
online banking systems. Industry plants uses geographically dispersed
controllers and sensors to collect data and regulate the plant.
The SETI project utilized millions of computer systems to search for
extra-terrestrial life. Also, the CERN integrates computer system from
all over the world to analyse the data produced by the accelerator and
collider to answer fundamental questions in science.~\cite{ghosh2014distributed}
These are just a few examples and can be easily extendend by numerous
more applications and possible future applications.

The state of the art technique to build such complex system that can
tolerate arbitrary faults is to use byzantine fault-tolerant state-machine
replication. With this technique every service can be modelled as a
set of services which replicate the whole systems state across all
nodes. Faulty replicas are masked behind a set of healthy replicas
which are operating in consensus.~\cite{rahli2018velisarios}

Most consensus protocols to build distributed systems are derived from
the original Paxos protocol from Leslie Lamport~\cite{lamport2001paxos}
which tend to be quite complex and only informal
described.~\cite{ongaro2014search}
As competitor RAFT was introduced which follows an approach to be
easy to understand and therefore easier to implement.

Yet building such systems is a tedious and error prone process and
as mentioned by~\cite{dragoi2015need} most of these systems are only
described in pseudo-code or formal but without executable code.
Due to the heavy parallel thinking required to build distributed
systems and the mostly informal reasoning makes the process quite
complex, expensive and time-consuming.

To tackle these problems and provide guarantees for the correctness and
security of the code one should use the highest standards known to mankind
today. That is, that one should prove the correctness of the formal specification and
through checking and refining the specification by a machine which produces
executable code, a correct and safe distributed system is modelled.~\cite{rahli2018velisarios}

Vincent Rahli et al. build a framework for the COQ theorem-prover
to model these complex systems which provides formal knowledge about distributed
systems. Using this framework this master thesis tries to implement
the basic RAFT consensus algorithm and compares it to the PBFT implementation
done by Vincent Rahli et al.~\cite{rahli2018velisarios}
Not part of the thesis are the proves for correctness.

This thesis is divided as follows. The first chapter explains the
mathematical foundation and the Velisarios framework. The second chapter
explains the RAFt protocol and compares it to the ones derived from Paxos.
Afterwards, the implementation is presented and explained. The fourth chapter
evaluates the implementation and the last one gives a short summary and a
brief outlook.



% In der modernen Welt sind Computer allgegenwärtig und mit den Entwicklungen
% der letzten 20 Jahre haben Netzwerke von Computern eine immer wichtigere Rolle
% für die Entwicklung der Menschheit gespielt. Sie ermöglichen physikalische
% Limitierung der Ressourcen eines Computers aufzuweichen durch Bündelung
% mehrerer Computer zu einem Virtuellen. Verteilte Systeme die sich einem Nutzer
% als ein koheräntes System darstellen, sind in vielen Anwendungsfällen essential
% für moderne Softwareanwendungen geworden, zum Beispiel Datenbanken die
% auf mehrere Computer verteilt sind. Solche verteilten Systeme ermöglichen
% es das Ausfälle einzelner Teilnehmer keinen Einfluss auf das Gesamtsystem haben,
% solange noch genügend Teilnehmer verbleiben. Solche Ausfälle können nicht nur
% durch dne Ausfall eines Computer entstehen, auch Netzwerkverbindungen können
% ausfallen oder extrem langsam sein. Damit Informationen zwischen den
% Instanzen gleich sind wurden Protokolle entwickelt, die auf die speziellen
% Gegebenheiten angepasst sind.

% Solche Protokolle sind bekanntermaßen schwer zu implementieren und stellen
% die Entwickler vor die Herausforderung wie man sie testet. Da sie darauf
% basieren, dass Teile eines verteilten Systems unerwartet ausfallen können,
% ist die Anzahl der Möglichen Fehler extrem Groß und schwer in definierten
% Umgebungen zu replizieren. Auch die Verifikation gestaltet sich als
% schwierig, da viele Interaktionen statt finden und keine zeitliche
% Kausalität angenommen werden kann.

% Mit Hilfe von Theorembeweisern und formalen Methoden der Theoretischen
% Informatik ist es Möglich Teile der Mathematik zu formalisieren und
% diese zur Verifikation von formalisierten Algorithmen zu verwenden.
% Die ``Logic of Events'' ist eine mathematische Theorie, um Protokolle
% in verteilten Systemen zu beschreiben.
% Die Theorie wurde in der Programmiersprache EventML umgesetzt, welches eine
% ML-Dialekt ist. sie besitzt eine Schnittstelle zu NUPRL, einem Theorembeweiser,
% um Eigenschaften verteilter Protokolle formal zu beweisen.
% Außerdem ist es mit EventML möglich ausführbare Programme zu erzeugen und
% diese auch in Simulationen zu testen und genauer zu untersuchen.

%Forschungsfragen:
% In dieser Arbeit werden die folgenden Forschungsfragen erörtert:
% \begin{itemize}
%   \item 
% \end{itemize}

% %Struktur:

% Im nächsten Abschnitt werden die Grundlagen für die ``Logic of Events'' nach
% Bickford hergeleitet und diese Eingeführt. Danach wird EventML
% als Programmiersprache genauer vorgestellt. In Abschnitt~\ref{sec_3} wird
% der Prozess von EventML zu asuführbaren Code genauer betrachtet. Danach wird gezeigt wie
% NUPRL Eigenschaften von verteilten Protokollen beweisen kann. Die Simulation
% von in EventML geschriebenen Systemen wird im Abschnitt~\ref{sec_5} gezeigt.
% Im letzten Abschnitt wird eine Zusammenfassung und ein Ausblick gegeben.
