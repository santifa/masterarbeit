% -*-LaTeX-*-


\documentclass[final]{article}
\usepackage[margin=1in]{geometry}

\usepackage{listings}
\usepackage{subfig}
\usepackage{float}
\usepackage[nomargin,inline]{fixme}

\floatstyle{ruled}
\restylefloat{figure}


%%%% FIXME

\fxusetheme{color}
\fxuseenvlayout{color}


%%%% MACROS

\input{../../tex/macros}


%%%% LISTINGS

\input{../../tex/eventml-listing}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% DOCUMENT STARTS HERE %%%%

\begin{document}


\title{Peterson's Algorithm in a Distributed Environment}
\author{Jason Wu \and Vincent Rahli}
%% 9/20/11
\date{\today}
\maketitle

\begin{abstract}
In this paper, we present a message passing version of Peterson's
algorithm suitable for a distributed environment.  Considering the
given properties of the environment, this version is meant to be
isomorphic to the original version of Peterson's algorithm.
%
%TODO
We also provide a concrete specification of the algorithm in \eml.
%along with statements of correctness in \nuprl.
\end{abstract}

\fxnote{(2011-11-03) We also plan an proving formal proofs of our
  protocol's correctness.}


\listoffixmes


\section{Introduction}

Peterson's algorithm is a well-known method for achieving mutual
exclusion in a shared memory environment.  We present an equivalent
version of the algorithm in a distributed environment.

In the next section, we describe the model of the problem.  We follow
by presenting the message passing version of Peterson's Algorithm is
presented in Section~\ref{sec:algorithm}.

In Section~\ref{sec:eventml}, a specification of the algorithm is
given in \eml.  Finally, we give a few concluding remarks.

\fxnote{(2011-11-03) along with statements of correctness in \nuprl.}


\section{Background information}

There are two processes, $P_1$ and $P_2$, and one shared resource $R$,
each in separate locations.  The processes have their own local memory
and may communicate with each other through messages.  In our
environment, messages can be delayed and received in a different order
than they were sent (i.e., we do not assume the FIFO condition).
However, messages cannot be lost or duplicated.  Access to the shared
resource is unsynchronized and this leads to the problem we wish to
solve: how can the two processes coordinate with each other to safely
access the shared resource?


%\subsection{Terminology}


\section{A message passing version of Peterson's algorithm (\mpp)}
\label{sec:algorithm}

The overall idea is to use a token to control access to the shared
resource.  Initially, one of the processes is given the token at the
start of the algorithm.  Whenever a process has the token, it may
access the shared resource.  Otherwise, it must request the token from
the other process.

It may be helpful to think of the token as a key that grants a process
access to the shared resource.  As time passes with the two processes
accessing the shared resource, the key gets passed back and forth
between the processes.

The behavior of a process may be succinctly described with the
following rules:
\begin{itemize}
\item When a process wants to enter its critical section (i.e., access
  the shared resource):
  \begin{itemize}
  \item If the process has the token, the process may enter its critical
    section.
  \item If the process does not have the token, it sends a request to
    the other process for the token and then waits for the token before
    entering its critical section.
  \end{itemize}

\item When a process receives a request for the token:
  \begin{itemize}
  \item If the process is not in its critical section, it will
    immediately send the token.
  \item If the process is in its critical section, it will delay sending
    the token until it has left its critical section.
  \end{itemize}
\end{itemize}


\subsection{Pseudocode}

\begin{figure}[!t]
\begin{tabular}{l@{\hspace*{1.0in}}ll}
\subfloat[Function called when a process wants to access the shared resource]
{\label{fig:EnterCriticalSection}\lstinputlisting[language=Java,basicstyle=\small]
  {code/EnterCriticalSection-v1a.txt}}&
\subfloat[Function called when a process receives a request message]
{\label{fig:HandleRequestMSG}\lstinputlisting[language=Java,basicstyle=\small]
  {code/HandleRequestMSG-v1a.txt}}
\end{tabular}
\caption{Pseudocode}
\label{fig:pseudocode}
\end{figure}

Pseudocode for the algorithm consists of two functions:
\textit{EnterCriticalSection} and \textit{HandleRequestMSG}.  When a
process would like to access the shared resource, it executes
\textit{EnterCriticalSection}.  Whenever a process receives a request
from the other process, it executes \textit{HandleRequestMSG}.

A process sends a request message and a token message to the other
process using the functions \textit{send\_requestMSG} and
\textit{send\_tokenMSG} respectively.  The function
\textit{wait\_for\_tokenMSG} allows a process to block until it
receives a token message.

The pseudocode given in Figure~\ref{fig:pseudocode} assumes the
function \textit{HandleRequestMSG}
(Figure~\ref{fig:pseudocode}\subref*{fig:HandleRequestMSG}) is atomic.
Each process maintains three Boolean variables: \textit{token},
\textit{busy}, and \textit{needToReply}.  The Boolean \textit{token}
is true when the process has the token.  The Boolean \textit{busy} is
true when the process is in (or wants to enter) the critical section.
The Boolean \textit{needToReply} is true when the process has received
a request while it was in (or wanted to enter) the critical section.
Only one of the two processes as its \textit{token} variable
intialized to true.  Both \textit{busy} and \textit{needToReply} are
initially false.

%Each process has a boolean variable, \textit{token}, and a lock, \textit{lock}.
%\textit{token} is true if and only if the process has the token.
%\textit{token} is intialized to true for only one of the processes.

\subsection{Correctness, Liveness, and Fairness}

We provide informal arguments for the correctness, liveness, and
fairness of \mpp.

\subsubsection{Correctness}

Notice that a process can only enter the critical section if it has
the token.  Also, notice that a process may only give up the token if
it is not in the critical section.  This implies that a process must
be in possession of the token when it is accessing the shared
resource.  Then, the correctness of the algorithm depends on the
existence of only one token at any point in time.  This unique token
may be in the hands of one of the processes or it may be in transit
(i.e., in the network as a message).

Initially, this is true because only one of the processes starts off
with the token.  Throughout the algorithm, a process can only obtain
the token if it receives a token message.  This token message must
have been sent by the other process (and the other process must have
the token in order to send a token message).  When the other process
sent the token message, it gave up its token.  Also, notice that the
token message can neither be duplicated nor lost in the network.  Both
the actions of the processes and the environment preserve the
existence of only one token.

\subsubsection{Liveness}

Suppose $P_1$ wants to use the shared resource.
%
If $P_1$ has the token, progress can be made (by $P_1$).
%
If $P_1$ does not have the token, it will send a request to $P_2$.
%
If $P_2$ is in its critical section, progress can be made (by $P_2$).
%
The last case is if $P_2$ is not in its critical section.  Then $P_2$
sends the token to $P_1$.
%
Before the tokens arrives at $P_1$, it is possible for $P_2$ to
request the token.  If $P_1$ receives the token before the token then
progress can be made by $P_1$.  Otherwise, $P_1$ receives the request
before the token.
%
Now, the only way for no progress to be made is if the token is passed
back and forth without either process accessing the shared resource.
%
%% Assume $P_1$ has requested the token and the token is in transit from
%% $P_2$ to $P_1$.
%% %
%% Consider the situation where $P_2$ requests the token and $P_1$
%% receives this request before receiving the token.
%
But, since $P_1$ wants to use the shared resource (i.e., it is in its
critical section), it will only send the token after it has made
progress (i.e., left its critical section).

In all cases, progress is made (i.e., one of the processes gets to
access the shared resource).


\subsubsection{Fairness}


We now argue that if a process, say $P_2$, would like to access the
shared resource, it is able to.
%
If $P_2$ has the token or the token is in transit to $P_2$, then we
are done.
%
Suppose $P_1$ has the token or the token is in transit to $P_1$.
%
According to the algorithm, $P_2$ sends a request to $P_1$ for the
token.
%
When $P_1$ receives the request, it acts depending on whether it is in
its critical section or not.
%
If $P_1$ is not in its critical section, it sends the token
immediately.
%
If $P_1$ is in its critical section, it sends the token as soon as it
leaves the critical section.
%
In either case, $P_2$ will eventually receive the token.

If the next immediate message $P_2$ receives is the token, it will be
able to access the shared resource.
%
However, consider the case where $P_1$ sends a request right after
sending the token and $P_2$ receives the request before receiving the
token.
%
According to the algorithm, $P_2$ will delay sending the token until
after it has left the critical section, guaranteeing fair access to
the shared resource.


\subsection{Comparison to the Original Version}

In the original version of Peterson's algorithm, if both processes
want to use the shared resource, the first process that enters its
critical section gets to go first.
%
The second process is guaranteed access before the first process can
use the resource again.


In \mpp, if both processes want to use the shared resource,
the process with the token gets to go first.
%
The second process is guaranteed access as soon as the first process
receives the request and is aware that the second process wants access
(i.e., the first process either sends the token to the second process
immediately or right after it leaves its critical section).
%


\subsection{Fault Tolerence}

We make a small note about the fault tolerence in the original version
of Peterson's algorithm and \mpp\.
%
In the original version, if a process failed while it was in the
critical section, the other process will be locked out of the shared
resource.
%
In \mpp, the same can happen.
%
In addition, in \mpp\ if a process fails while it has the token,
regardless of whether it is in the critical section or not, the other
process is then locked out of the shared resource.
%
Obviously, it appears that this version has weaker fault tolerence
than the original version.
%

We believe that this is the best one can do given the properties of
the environment.
%
For any distributed version of Peterson's algorithm that does not use
a token, if a process fails at any time, the other process will always
be locked out of the shared resource.
%
The other process will attempt to coordinate with the failed process
in order to safely access the shared resource, but will end up waiting
forever for a reply to arrive.
%
It is impossible for a process to distinguish between the failure of
the other process, an infinitely-delayed message, or the fact that the
other process is staying in the critical section.
%

\section{\eml\ specification}
\label{sec:eventml}

In this section, we present the \eml\ specification of \mpp.
%
This specification defines two proxies that provide synchronized
access to a shared resource for two users.  Each proxy works on behalf
of a one user.


\subsection{Specification name}

The first thing one does when specifying a protocol in \eml\ is give a
name to it:
\begin{emlcode}
  \lstinputlisting[language=EventML,basicstyle=\small]{code/MutualExclusion-v3-specification.esh}
\end{emlcode}


\subsection{Imports}

\eml\ provides a snapshot of \nuprl's library containing functions
that can be imported individually for use in specifications.  For
example, our specification uses a state machine called
\lstinline{SM4-class-du}:
\begin{emlcode}
  \lstinputlisting[language=EventML,basicstyle=\small]{code/MutualExclusion-v3-imports.esh}
\end{emlcode}


\subsection{Parameters}

A specification parameter can be viewed as a global variable that has
to be instantiated in order to run the program corresponding to the
specification.
%
The shared resource is located at location \lstinline{sr}.
%
The two proxies providing synchronized access of the shared resource
are running at the two locations \lstinline{proc1} and
\lstinline{proc2}.
%
Finally, we define a fourth parameter, namely
\lstinline{initial_token}, which is the location of the process that
initially gets the token.
\begin{emlcode}
  \lstinputlisting[language=EventML,basicstyle=\small]{code/MutualExclusion-v3-parameters.esh}
\end{emlcode}
(Note that \lstinline{initial_token} has to be either
\lstinline{proc1} or \lstinline{proc2} but \eml\ currently does not
allow one to specify that.)


\subsection{Messages}

In an \eml\ specification we must specify all the types of messages
used in the specification.
%
\lstinline{MPP} uses six kinds of messages.  A process can receive two
kinds of input messages: a $\CONSatoms{use sr}$ message is sent to a
process by a user to request the use of the shared resource; a
$\CONSatoms{leave cs}$ is sent from the shared resource to a process
when this process leaves it.  A process can output two kinds of
messages: a $\CONSatoms{enter sr}$ is sent by a process to the shared
resource process when starting to use the shared resource
\begin{emlcode}
  \lstinputlisting[language=EventML,basicstyle=\small]{code/MutualExclusion-v3-messages.esh}
\end{emlcode}


\subsection{Protocol}

\begin{emlcode}
  \lstinputlisting[language=EventML,basicstyle=\small]{code/MutualExclusion-v3-state.esh}
\end{emlcode}

\begin{emlcode}
  \lstinputlisting[language=EventML,basicstyle=\small]{code/MutualExclusion-v3-classes.esh}
\end{emlcode}


\section{\nuprl\ proofs}


\section{Conclusion}


\end{document}
